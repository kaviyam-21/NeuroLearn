python : 
`trust_remote_code` 
is not supported 
anymore.
At line:1 char:1
+ python handwriting_r
ecognition_pytorch.py 
--use_hf --epochs 1 
--batch ...
+ ~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~
~~~~~
    + CategoryInfo    
          : NotSpeci  
  fied: (`trust_rem   
 ote_c...ported an    
ymore.:String) []    
, RemoteException
    + FullyQualifiedE 
   rrorId : NativeCo  
  mmandError
 
Please check that the 
Hugging Face dataset 
'Teklia/IAM-line' 
isn't based on a 
loading script and 
remove 
`trust_remote_code`.
If the dataset is 
based on a loading 
script, please ask 
the dataset author to 
remove it and convert 
it to a standard 
format like Parquet.
Warning: You are 
sending 
unauthenticated 
requests to the HF 
Hub. Please set a 
HF_TOKEN to enable 
higher rate limits 
and faster downloads.
`trust_remote_code` 
is not supported 
anymore.
Please check that the 
Hugging Face dataset 
'Teklia/IAM-line' 
isn't based on a 
loading script and 
remove 
`trust_remote_code`.
If the dataset is 
based on a loading 
script, please ask 
the dataset author to 
remove it and convert 
it to a standard 
format like Parquet.
Using Hugging Face dataset: Teklia/IAM-line
Traceback (most 
recent call last):
  File "C:\Users\kaviy
am\Desktop\hand\hands\
HandwrittenTextRecogni
tion-1\handwriting_rec
ognition_pytorch.py", 
line 119, in <module>
    train_loss = 
run_epoch(e, net, 
train_loader, 
optimizer, criterion, 
device, True)
                 ^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^
  File "C:\Users\kaviy
am\Desktop\hand\hands\
HandwrittenTextRecogni
tion-1\handwriting_rec
ognition_pytorch.py", 
line 54, in run_epoch
    for i, (x, y) in 
enumerate(dataloader):
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\dataloader
.py", line 741, in 
__next__
    data = 
self._next_data()
           
^^^^^^^^^^^^^^^^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\dataloader
.py", line 1548, in 
_next_data
    return self._proce
ss_data(data, 
worker_id)
           ^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\dataloader
.py", line 1586, in 
_process_data
    data.reraise()
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\_utils.py", line 
775, in reraise
    raise exception
RuntimeError: Caught 
RuntimeError in 
DataLoader worker 
process 0.
Original Traceback 
(most recent call 
last):
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\wor
ker.py", line 358, in 
_worker_loop
    data = 
fetcher.fetch(index)  
# type: ignore[possibl
y-undefined]
           
^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\fet
ch.py", line 57, in 
fetch
    return 
self.collate_fn(data)
           
^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\col
late.py", line 401, 
in default_collate
    return 
collate(batch, collate
_fn_map=default_collat
e_fn_map)
           ^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\col
late.py", line 214, 
in collate
    return [
           ^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\col
late.py", line 215, 
in <listcomp>
    collate(samples, c
ollate_fn_map=collate_
fn_map)
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\col
late.py", line 155, 
in collate
    return collate_fn_
map[elem_type](batch, 
collate_fn_map=collate
_fn_map)
           ^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\col
late.py", line 288, 
in 
collate_numpy_array_fn
    return collate([to
rch.as_tensor(b) for 
b in batch], collate_f
n_map=collate_fn_map)
           ^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\col
late.py", line 155, 
in collate
    return collate_fn_
map[elem_type](batch, 
collate_fn_map=collate
_fn_map)
           ^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^^^^
^^^^^^^^
  File "C:\Users\kaviy
am\AppData\Local\Progr
ams\Python\Python311\L
ib\site-packages\torch
\utils\data\_utils\col
late.py", line 275, 
in collate_tensor_fn
    return 
torch.stack(batch, 0, 
out=out)
           ^^^^^^^^^^^
^^^^^^^^^^^^^^^^^^^
RuntimeError: stack 
expects each tensor 
to be equal size, but 
got [1, 128, 1352] at 
entry 0 and [1, 128, 
842] at entry 1

